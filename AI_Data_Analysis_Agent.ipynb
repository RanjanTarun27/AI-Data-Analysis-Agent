{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOctHFqcqHUQMEMC1Z/Q2q8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RanjanTarun27/AI-Data-Analysis-Agent/blob/main/AI_Data_Analysis_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbMdwgFBZik-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tempfile\n",
        "import csv\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from agno.models.openai import OpenAIChat\n",
        "from phi.agent.duckdb import DuckDbAgent\n",
        "from agno.tools.pandas import PandasTools\n",
        "import re\n",
        "\n",
        "# Function to preprocess and save the uploaded file\n",
        "def preprocess_and_save(file):\n",
        "    try:\n",
        "        # Read the uploaded file into a DataFrame\n",
        "        if file.name.endswith('.csv'):\n",
        "            df = pd.read_csv(file, encoding='utf-8', na_values=['NA', 'N/A', 'missing'])\n",
        "        elif file.name.endswith('.xlsx'):\n",
        "            df = pd.read_excel(file, na_values=['NA', 'N/A', 'missing'])\n",
        "        else:\n",
        "            st.error(\"Unsupported file format. Please upload a CSV or Excel file.\")\n",
        "            return None, None, None\n",
        "\n",
        "        # Ensure string columns are properly quoted\n",
        "        for col in df.select_dtypes(include=['object']):\n",
        "            df[col] = df[col].astype(str).replace({r'\"': '\"\"'}, regex=True)\n",
        "\n",
        "        # Parse dates and numeric columns\n",
        "        for col in df.columns:\n",
        "            if 'date' in col.lower():\n",
        "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "            elif df[col].dtype == 'object':\n",
        "                try:\n",
        "                    df[col] = pd.to_numeric(df[col])\n",
        "                except (ValueError, TypeError):\n",
        "                    # Keep as is if conversion fails\n",
        "                    pass\n",
        "\n",
        "        # Create a temporary file to save the preprocessed data\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\") as temp_file:\n",
        "            temp_path = temp_file.name\n",
        "            # Save the DataFrame to the temporary CSV file with quotes around string fields\n",
        "            df.to_csv(temp_path, index=False, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "        return temp_path, df.columns.tolist(), df  # Return the DataFrame as well\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error processing file: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"ðŸ“Š Data Analyst Agent\")\n",
        "\n",
        "# Sidebar for API keys\n",
        "with st.sidebar:\n",
        "    st.header(\"API Keys\")\n",
        "    openai_key = st.text_input(\"Enter your OpenAI API key:\", type=\"password\")\n",
        "    if openai_key:\n",
        "        st.session_state.openai_key = openai_key\n",
        "        st.success(\"API key saved!\")\n",
        "    else:\n",
        "        st.warning(\"Please enter your OpenAI API key to proceed.\")\n",
        "\n",
        "# File upload widget\n",
        "uploaded_file = st.file_uploader(\"Upload a CSV or Excel file\", type=[\"csv\", \"xlsx\"])\n",
        "\n",
        "if uploaded_file is not None and \"openai_key\" in st.session_state:\n",
        "    # Preprocess and save the uploaded file\n",
        "    temp_path, columns, df = preprocess_and_save(uploaded_file)\n",
        "\n",
        "    if temp_path and columns and df is not None:\n",
        "        # Display the uploaded data as a table\n",
        "        st.write(\"Uploaded Data:\")\n",
        "        st.dataframe(df)  # Use st.dataframe for an interactive table\n",
        "\n",
        "        # Display the columns of the uploaded data\n",
        "        st.write(\"Uploaded columns:\", columns)\n",
        "\n",
        "        # Configure the semantic model with the temporary file path\n",
        "        semantic_model = {\n",
        "            \"tables\": [\n",
        "                {\n",
        "                    \"name\": \"uploaded_data\",\n",
        "                    \"description\": \"Contains the uploaded dataset.\",\n",
        "                    \"path\": temp_path,\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Initialize the DuckDbAgent for SQL query generation\n",
        "        duckdb_agent = DuckDbAgent(\n",
        "            model=OpenAIChat(model=\"gpt-4\", api_key=st.session_state.openai_key),\n",
        "            semantic_model=json.dumps(semantic_model),\n",
        "            tools=[PandasTools()],\n",
        "            markdown=True,\n",
        "            add_history_to_messages=False,  # Disable chat history\n",
        "            followups=False,  # Disable follow-up queries\n",
        "            read_tool_call_history=False,  # Disable reading tool call history\n",
        "            system_prompt=\"You are an expert data analyst. Generate SQL queries to solve the user's query. Return only the SQL query, enclosed in ```sql ``` and give the final answer.\",\n",
        "        )\n",
        "\n",
        "        # Initialize code storage in session state\n",
        "        if \"generated_code\" not in st.session_state:\n",
        "            st.session_state.generated_code = None\n",
        "\n",
        "        # Main query input widget\n",
        "        user_query = st.text_area(\"Ask a query about the data:\")\n",
        "\n",
        "        # Add info message about terminal output\n",
        "        st.info(\"ðŸ’¡ Check your terminal for a clearer output of the agent's response\")\n",
        "\n",
        "        if st.button(\"Submit Query\"):\n",
        "            if user_query.strip() == \"\":\n",
        "                st.warning(\"Please enter a query.\")\n",
        "            else:\n",
        "                try:\n",
        "                    # Show loading spinner while processing\n",
        "                    with st.spinner('Processing your query...'):\n",
        "                        # Get the response from DuckDbAgent\n",
        "\n",
        "                        response1 = duckdb_agent.run(user_query)\n",
        "\n",
        "                        # Extract the content from the RunResponse object\n",
        "                        if hasattr(response1, 'content'):\n",
        "                            response_content = response1.content\n",
        "                        else:\n",
        "                            response_content = str(response1)\n",
        "                        response = duckdb_agent.print_response(\n",
        "                        user_query,\n",
        "                        stream=True,\n",
        "                        )\n",
        "\n",
        "                    # Display the response in Streamlit\n",
        "                    st.markdown(response_content)\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error generating response from the DuckDbAgent: {e}\")\n",
        "                    st.error(\"Please try rephrasing your query or check if the data format is correct.\")"
      ]
    }
  ]
}